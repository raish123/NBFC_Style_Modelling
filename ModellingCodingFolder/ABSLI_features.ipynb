{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cffe78e-5197-4b94-bfa3-dda54ce0a513",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance saved to abli_feature_importance_gradient.csv\n"
     ]
    }
   ],
   "source": [
    "model_xgb_final = xgb.Booster()\n",
    "model_xgb_final.load_model('li_intent_model_2025-10-07.json')\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = model_xgb_final.get_score(importance_type='gain')\n",
    "\n",
    "# Convert to DataFrame\n",
    "importance_df = pd.DataFrame(list(feature_importance.items()), columns=['Feature', 'Gain Value'])\n",
    "importance_df = importance_df.sort_values('Gain Value', ascending=False)\n",
    "importance_df['Feature Importance'] = importance_df['Gain Value'] / importance_df['Gain Value'].sum()\n",
    "# Save to CSV\n",
    "filename = 'abli_feature_importance_gradient.csv'\n",
    "importance_df.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"Feature importance saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe1dea5a-ad58-42b1-b547-d49bde3139cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import pandas_gbq\n",
    "import shap\n",
    "import seaborn as sns\n",
    "import cloudpickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import itertools\n",
    "\n",
    "from google.cloud import bigquery, storage\n",
    "from matplotlib import pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from box import Box\n",
    "from scipy.stats import chi2_contingency, f_oneway\n",
    "from statsmodels.formula.api import ols\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "\n",
    "client = bigquery.Client()\n",
    "store = storage.Client()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1e5b7df-1a85-49b7-95e5-c94fe8c1ec53",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%bigquery df\n",
    "\n",
    "SELECT snapshot_partition, count(*)\n",
    "FROM\n",
    "`abcd-dataplatform.abcd_data_science_app.abhi_intent_model_investment_features_raw`\n",
    "\n",
    "GROUP BY 1\n",
    "order by 1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8751f5f0-40fb-405d-a7b7-8b2146d2df82",
   "metadata": {
    "tags": []
   },
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4274372-e8b4-4e23-b4d7-44bd048db7b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Model Training-OOT base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76de23e3-801b-49d3-bc25-00bbda4103b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f4bd3f2ead0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY = \"\"\"\n",
    "CREATE OR REPLACE TABLE `abcd-dataplatform.abcd_data_science_app.li_intent_model_combined_features`\n",
    "PARTITION BY snapshot_partition\n",
    "AS (\n",
    "    WITH cs_base AS (\n",
    "        SELECT\n",
    "            *\n",
    "        FROM\n",
    "            `abcd-dataplatform.abcd_data_science_app.li_intent_model_targets`\n",
    "    ),\n",
    "\n",
    "    cashflow_features AS (\n",
    "        SELECT\n",
    "            *\n",
    "        FROM\n",
    "            `abcd-dataplatform.abcd_data_science_app.abhi_intent_model_cashflow_features_raw`\n",
    "    ),\n",
    "    \n",
    "    bank_features AS (\n",
    "        SELECT\n",
    "            *\n",
    "        FROM\n",
    "            `abcd-dataplatform.abcd_data_science_app.abhi_intent_model_bank_features_raw`\n",
    "    ),\n",
    "    \n",
    "    loan_features AS (\n",
    "        SELECT\n",
    "            *\n",
    "        FROM\n",
    "            `abcd-dataplatform.abcd_data_science_app.abhi_intent_model_loan_features_raw`\n",
    "    ),\n",
    "    \n",
    "    credit_card_features AS (\n",
    "        SELECT\n",
    "            *\n",
    "        FROM\n",
    "            `abcd-dataplatform.abcd_data_science_app.abhi_intent_model_credit_card_features_raw`\n",
    "    ),\n",
    "    \n",
    "    investment_features AS (\n",
    "        SELECT\n",
    "            *\n",
    "        FROM\n",
    "            `abcd-dataplatform.abcd_data_science_app.abhi_intent_model_investment_features_raw`\n",
    "    ),\n",
    "    \n",
    "    utility_features AS (\n",
    "        SELECT\n",
    "            *\n",
    "        FROM\n",
    "            `abcd-dataplatform.abcd_data_science_app.abhi_intent_model_utility_features_raw`\n",
    "    ),\n",
    "    \n",
    "    spend_features AS (\n",
    "        SELECT\n",
    "            *\n",
    "        FROM\n",
    "            `abcd-dataplatform.abcd_data_science_app.abhi_intent_model_topspend_features_raw`\n",
    "    ),\n",
    "    \n",
    "    insurance_features AS (\n",
    "        SELECT\n",
    "            *\n",
    "        FROM\n",
    "            `abcd-dataplatform.abcd_data_science_app.abhi_intent_model_insurance_features_raw`\n",
    "    ),\n",
    "    \n",
    "    Anagog_features AS (\n",
    "        SELECT \n",
    "        * \n",
    "        FROM `abcd-dataplatform.abcd_data_science_app.hi_intent_models_anagog_features_raw`\n",
    "    ),\n",
    "        \n",
    "    inapp_features AS(\n",
    "        SELECT \n",
    "        * \n",
    "        FROM `abcd-dataplatform.abcd_data_science_app.hi_intent_models_inapp_dha_interacted_features_raw`\n",
    "    ),\n",
    "        \n",
    "    cust_age_features AS(\n",
    "    SELECT \n",
    "    *\n",
    "    FROM `abcd-dataplatform.abcd_data_science_app.hi_intent_models_cust_age_pin_features_raw`\n",
    "    ),\n",
    "    \n",
    "--    exp_loan_features AS (\n",
    "--  SELECT \n",
    "--    CUSTOMER_ID AS mobilenumber,\n",
    "--    * EXCEPT(CUSTOMER_ID)\n",
    "--    FROM `abcd-dataplatform.abcd_data_science_app.abhi_intent_model_bureau_loan_amount_features_raw`\n",
    "--    ),\n",
    "    \n",
    "        \n",
    "        \n",
    "    joined_base AS (\n",
    "        SELECT\n",
    "            base.*,\n",
    "            cf.* EXCEPT(mobilenumber, snapshot_partition), \n",
    "            bf.* EXCEPT(mobilenumber, snapshot_partition),\n",
    "            lf.* EXCEPT(mobilenumber, snapshot_partition),\n",
    "            ccf.* EXCEPT(mobilenumber, snapshot_partition),\n",
    "            invf.* EXCEPT(mobilenumber, snapshot_partition),\n",
    "            uf.* EXCEPT(mobilenumber, snapshot_partition),\n",
    "            sf.* EXCEPT(mobilenumber, snapshot_partition),\n",
    "            insurf.* EXCEPT(mobilenumber, snapshot_partition),\n",
    "            anagog_f.* EXCEPT(customer_id, mobilenumber, snapshot_partition),\n",
    "            inapp_f.* EXCEPT(customer_id, mobilenumber, snapshot_partition),\n",
    "            cust_age_f.* EXCEPT(customer_id, mobilenumber, snapshot_partition),\n",
    "--            exp_loan_f.* EXCEPT(mobilenumber, snapshot_partition)\n",
    "            \n",
    "            \n",
    "            \n",
    "        FROM\n",
    "            cs_base AS base\n",
    "        LEFT JOIN\n",
    "            cashflow_features AS cf\n",
    "        USING(mobilenumber, snapshot_partition)\n",
    "        \n",
    "        LEFT JOIN\n",
    "            bank_features AS bf\n",
    "        USING(mobilenumber, snapshot_partition) \n",
    "        \n",
    "        LEFT JOIN\n",
    "            loan_features AS lf\n",
    "        USING(mobilenumber, snapshot_partition) \n",
    "        \n",
    "        \n",
    "        LEFT JOIN\n",
    "            credit_card_features AS ccf\n",
    "        USING(mobilenumber, snapshot_partition)\n",
    "        \n",
    "        LEFT JOIN\n",
    "            investment_features AS invf\n",
    "        USING(mobilenumber, snapshot_partition)\n",
    "        \n",
    "        LEFT JOIN\n",
    "            utility_features AS uf\n",
    "        USING(mobilenumber, snapshot_partition)\n",
    "        \n",
    "         LEFT JOIN\n",
    "            spend_features AS sf\n",
    "        USING(mobilenumber, snapshot_partition)\n",
    "        \n",
    "        LEFT JOIN\n",
    "            insurance_features AS insurf\n",
    "        USING(mobilenumber, snapshot_partition)\n",
    "        \n",
    "        LEFT JOIN\n",
    "            Anagog_features AS anagog_f\n",
    "        USING(mobilenumber, snapshot_partition)\n",
    "        \n",
    "        LEFT JOIN\n",
    "            inapp_features AS inapp_f\n",
    "        USING(mobilenumber, snapshot_partition)\n",
    "        \n",
    "        LEFT JOIN\n",
    "            cust_age_features AS cust_age_f\n",
    "        USING(mobilenumber, snapshot_partition)\n",
    "        \n",
    "--        LEFT JOIN\n",
    "--            exp_loan_features AS exp_loan_f\n",
    "--        USING(mobilenumber, snapshot_partition)\n",
    ")\n",
    "    \n",
    "    SELECT *\n",
    "    FROM joined_base\n",
    "\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# sms_grad_features = client.query(QUERY).to_dataframe()\n",
    "# sms_grad_features.info()\n",
    "\n",
    "client.query(QUERY).result()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "11620589-3f8c-4794-a2f7-10f8d95e31a6",
   "metadata": {},
   "source": [
    "%%bigquery df\n",
    "\n",
    "SELECT * FROM `abcd-dataplatform.abcd_data_science_app.hi_intent_model_combined_features`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13af2bfd-acaa-49da-a40d-8ddc83cf8415",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289528cd-1194-4ddf-9938-d9c5417c0e7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Stratified Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4bb1f78-2f76-41b0-af6e-54a7bdf3018a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285ebdfec98e4a8c9342bc4c65a84ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "\n",
    "CREATE OR REPLACE TABLE\n",
    "  `abcd-dataplatform.abcd_data_science_app.li_base_data` AS (\n",
    "  WITH\n",
    "    counts AS (\n",
    "    SELECT\n",
    "      snapshot_partition,\n",
    "      abli_target,\n",
    "      COUNT(*) AS cnt\n",
    "    FROM\n",
    "      `abcd-dataplatform.abcd_data_science_app.li_intent_model_combined_features`\n",
    "    WHERE\n",
    "      snapshot_partition IN ('2024-12-31',\n",
    "        '2025-01-31',\n",
    "        '2025-02-28',\n",
    "        '2025-03-31')\n",
    "    GROUP BY\n",
    "      snapshot_partition,\n",
    "      abli_target ),\n",
    "    with_sample AS (\n",
    "    SELECT\n",
    "      f.*,\n",
    "      ROW_NUMBER() OVER (PARTITION BY snapshot_partition, final_target ORDER BY RAND()) AS rn\n",
    "    FROM\n",
    "      `abcd-dataplatform.abcd_data_science_app.li_intent_model_combined_features` f\n",
    "    WHERE\n",
    "      snapshot_partition IN ('2024-12-31',\n",
    "        '2025-01-31',\n",
    "        '2025-02-28',\n",
    "        '2025-03-31') )\n",
    "  SELECT\n",
    "    w.* EXCEPT(rn)\n",
    "  FROM\n",
    "    with_sample w\n",
    "  JOIN\n",
    "    counts c\n",
    "  ON\n",
    "    w.snapshot_partition = c.snapshot_partition\n",
    "    AND w.final_target = c.abli_target\n",
    "  WHERE\n",
    "    rn <= SAFE_CAST(c.cnt * 0.1 AS INT64) \n",
    ");"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3551d90e-6a8c-45df-a85f-2f86e847adf1",
   "metadata": {
    "tags": []
   },
   "source": [
    "table_name = 'hi_base_data'\n",
    " \n",
    "pandas_gbq.to_gbq(\n",
    "    dataframe = hi_base_data,\n",
    "    destination_table=f'abcd_data_science_app.{table_name}',\n",
    "    project_id='abcd-dataplatform',\n",
    "    if_exists='append'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da981b59-3ec6-4e47-b4d3-3a5810420cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d960b1afde243bb82286815a893f8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab5c98d0f1c4842af9c7aa5d48f106d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%bigquery hi_base_data\n",
    "\n",
    "SELECT * FROM `abcd-dataplatform.abcd_data_science_app.li_base_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb89c885-d5d0-4402-9cb4-5a8ecf785679",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1776619 entries, 0 to 1776618\n",
      "Columns: 866 entries, customer_id to mobile_device_price\n",
      "dtypes: Int64(89), datetime64[us](1), dbdate(1), float64(755), object(20)\n",
      "memory usage: 12.8 GB\n"
     ]
    }
   ],
   "source": [
    "hi_base_data.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5469ad38-a59a-4579-bf3b-dc7cab954bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005972017635745199"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi_base_data.final_target.sum() / hi_base_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6391be6-4247-46d5-b7ef-b83e979510ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tier   final_target\n",
       "Tier1  0               247330\n",
       "       1                  209\n",
       "Tier2  0               449208\n",
       "       1                  261\n",
       "Tier3  0               761394\n",
       "       1                  464\n",
       "NaN    0               317626\n",
       "       1                  127\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi_base_data[['tier', 'final_target']].value_counts(dropna=False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffd96a67-3481-4750-a6fc-ca8ee600087b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_cols = [\n",
    "    'latest_txn_date_ALL', \n",
    "    'latest_txn_date_L1M', \n",
    "    'latest_txn_date_L3M', \n",
    "    'latest_txn_date_L6M', \n",
    "    'latest_txn_date_L9M',\n",
    "    'latest_txn_date_L12M'\n",
    "]\n",
    "\n",
    "categorical_cols = [\n",
    "    'most_frequent_bank', \n",
    "    'bank_with_highest_avg_balance', \n",
    "    'max_spend_category', \n",
    "    'bank_w_highest_cc_limit',\n",
    "    'bank_w_highest_loan_emi_due',\n",
    "    'IsGymLover',\n",
    "    'IsSingle',\n",
    "    'IsParent',\n",
    "    'employment_type',\n",
    "    'tier',\n",
    "    'age_bracket'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd9b1d18-5024-47d6-a43c-d982c8884cb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_feature_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 3,\n",
    "    'n_jobs': 24,\n",
    "    'learning_rate': 0.01,\n",
    "    # 'n_estimators': 500,\n",
    "    # 'gamma': 2,\n",
    "    'subsample': 0.75,\n",
    "    'colsample_bytree': 0.8,\n",
    "    # 'lambda': 0.1,\n",
    "    # 'alpha': 0.1\n",
    "    'eval_metric': 'logloss'\n",
    "    # 'scale_pos_weight': 666\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533fc982-ab39-4e64-9356-a35e90346d21",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Feature Selection Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ba0e090-5fee-4e0f-8b54-b2ab411cfb99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modifying Date columns:\n",
      "\tlatest_txn_date_ALL\n",
      "\tlatest_txn_date_L1M\n",
      "\tlatest_txn_date_L3M\n",
      "\tlatest_txn_date_L6M\n",
      "\tlatest_txn_date_L9M\n",
      "\tlatest_txn_date_L12M\n",
      "\n",
      "Modifying Categorical columns:\n",
      "\tmost_frequent_bank\n",
      "\tbank_with_highest_avg_balance\n",
      "\tmax_spend_category\n",
      "\tbank_w_highest_cc_limit\n",
      "\tbank_w_highest_loan_emi_due\n",
      "\tIsGymLover\n",
      "\tIsSingle\n",
      "\tIsParent\n",
      "\temployment_type\n",
      "\ttier\n",
      "\tage_bracket\n"
     ]
    }
   ],
   "source": [
    "print('Modifying Date columns:')\n",
    "for date_col in date_cols:\n",
    "    if date_col in hi_base_data.columns:\n",
    "        print(f'\\t{date_col}')\n",
    "        hi_base_data[date_col] = (pd.to_datetime(hi_base_data.loc[:, 'snapshot_partition']) + pd.DateOffset(months=1) - pd.DateOffset(days=1) - pd.to_datetime(hi_base_data.loc[:, date_col])).dt.days\n",
    "\n",
    "print('\\nModifying Categorical columns:')\n",
    "# Ensure categorical columns have the dtype 'category'\n",
    "for col in categorical_cols:\n",
    "    if col in hi_base_data.columns:\n",
    "        print(f'\\t{col}')\n",
    "        hi_base_data[col] = hi_base_data[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba6e45f6-b044-47a4-b2e3-141aeb13eb80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare the training data by filtering out unwanted columns\n",
    "train_features = hi_base_data.loc[:, ~(hi_base_data.columns.str.contains('customer_id') |\n",
    "                                  hi_base_data.columns.str.contains('mobilenumber') |\n",
    "                                  hi_base_data.columns.str.contains('registration_date') |\n",
    "                                  hi_base_data.columns.str.contains('app_target') |\n",
    "                                  hi_base_data.columns.str.contains('final_target') |\n",
    "                                  hi_base_data.columns.str.contains('sms_target') |\n",
    "                                  hi_base_data.columns.str.contains('mobile_device_price') |\n",
    "                                  hi_base_data.columns.str.contains('snapshot_partition'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99cfab10-3408-4c89-ba29-dff81b07e253",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = train_features.drop(columns=['age', 'cashflow_num_months'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "146deb0b-0a2f-49ae-9e38-3cde1d9a3e61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_column = 'abli_target'\n",
    "y_train = hi_base_data[target_column]\n",
    "train_features = train_features.drop(columns=[target_column])\n",
    "\n",
    "# Create a DMatrix for training\n",
    "dtrain = xgb.DMatrix(train_features, label=y_train, enable_categorical=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "356ad44a-669b-459b-ae4b-e26dc6a78509",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 40s, sys: 0 ns, total: 21min 40s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train the model using XGBoost's train function\n",
    "model_xgb = xgb.train(params=xgb_feature_params, dtrain=dtrain, num_boost_round=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3410e42f-2e7e-4825-a877-bb1be08d1af1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22min 45s, sys: 0 ns, total: 22min 45s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "explainer = shap.TreeExplainer(model_xgb)\n",
    "shap_values = explainer.shap_values(dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8e69c5f-bf3e-4f9f-9169-9d1288c3a6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filtered columns: 275\n",
      "Number of filtered columns: 275\n"
     ]
    }
   ],
   "source": [
    "# Convert SHAP values to a DataFrame with column names from the DMatrix\n",
    "shap_abs = pd.DataFrame(shap_values, columns=train_features.columns).abs().mean()\n",
    "\n",
    "# Filter columns where the mean absolute SHAP value is greater than 0.001\n",
    "filtered_columns = shap_abs[shap_abs > 0.001].index.tolist()\n",
    "\n",
    "# Output the number of filtered columns\n",
    "print(f\"Number of filtered columns: {len(filtered_columns)}\")\n",
    "print(f\"Number of filtered columns: {len(set(filtered_columns))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d2f2e64-734c-4b67-b212-d877916a6e0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define mandatory columns you want to keep\n",
    "forced_columns = ['tier', 'age_bracket', 'dha_interacted', 'IsSingle', 'IsParent']\n",
    "forced_columns = [col for col in forced_columns if shap_abs.loc[col] > 0.0001]\n",
    "forced_columns = ['IsParent']\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "77671a80-8746-4f47-ae21-cfa80f4d585e",
   "metadata": {
    "tags": []
   },
   "source": [
    "shap_abs.loc['IsParent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddcce906-a25c-48c5-8b38-83d6848d311f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_columns.extend([col for col in forced_columns if col not in filtered_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82bce8db-b84d-458a-95d8-0f1a458298a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns = [col for col in filtered_columns if col not in categorical_cols]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "304fcd26-4f6a-41ee-8dbc-7058e233c604",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate the correlation matrix in parallel\n",
    "columns = final_columns\n",
    "n_jobs = 24  # Use all available cores\n",
    "\n",
    "correlation_matrix = train_features[columns].corr(method=\"pearson\", min_periods=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bfb4ad4-2b64-48b2-82a7-ee4a3182ae3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 19min 27s, sys: 27min 17s, total: 1h 46min 45s\n",
      "Wall time: 8min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "columns = final_columns\n",
    "ddf = dd.from_pandas(train_features[final_columns], npartitions=32)\n",
    "correlation_matrix = ddf.corr().compute()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6990d22e-cefe-47d2-98ed-a62b4c404ab9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Function to compute correlation for each pair of columns\n",
    "def compute_corr(col1, col2, data):\n",
    "    return data[col1].corr(data[col2], min_periods=1)\n",
    "\n",
    "# Generate the correlation matrix in parallel\n",
    "columns = final_columns\n",
    "n_jobs = 24  # Use all available cores\n",
    "\n",
    "# Generate the correlation matrix in parallel\n",
    "correlation_values = Parallel(n_jobs=n_jobs)(\n",
    "    delayed(compute_corr)(col1, col2, train_features)\n",
    "    for col1 in columns for col2 in columns\n",
    ")\n",
    "\n",
    "# Reshape the list into a square matrix\n",
    "correlation_matrix = pd.DataFrame(\n",
    "    np.array(correlation_values).reshape(len(columns), len(columns)),\n",
    "    index=columns, columns=columns\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "65337f20-6332-45fb-9c58-609c1025700d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plot the heatmap\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(correlation_matrix.abs(), annot=True, cmap='coolwarm', fmt=\".3f\", linewidths=0.5, annot_kws={\"size\": 10})\n",
    "plt.title('Parallelized Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6d131ad-9658-4b07-a29a-c86d5fba9835",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2149"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff = 0.6\n",
    "upper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "correlated_pairs = [(column, row) for column in upper_triangle.columns for row in upper_triangle.index if upper_triangle.at[row, column] > cutoff]\n",
    "\n",
    "len(correlated_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ec1e483-67f7-43a8-9083-7eec44ee5bfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_set = set()\n",
    "for column, row in correlated_pairs:\n",
    "    if shap_abs.loc[column] > shap_abs.loc[row]:\n",
    "        drop_set.add(row)\n",
    "    else:\n",
    "        drop_set.add(column)\n",
    "\n",
    "drop_set = list(drop_set)\n",
    "filtered_features = [column for column in filtered_columns if column not in drop_set]\n",
    "len(filtered_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc68d127-676c-4a66-9876-4e47bba0568d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_pearson_corr(col1, col2, data):\n",
    "    return data[col1].corr(data[col2], min_periods=1)\n",
    "\n",
    "# Function to compute Cram√©r's V for categorical features\n",
    "def cramers_v(col1, col2, data):\n",
    "    contingency_table = pd.crosstab(data[col1], data[col2])\n",
    "    chi2, _, _, _ = chi2_contingency(contingency_table)\n",
    "    n = contingency_table.sum().sum()\n",
    "    r, k = contingency_table.shape\n",
    "    return np.sqrt(chi2 / (n * (min(k - 1, r - 1))))\n",
    "\n",
    "# Function to compute Eta Squared for numerical vs categorical\n",
    "def compute_eta_squared(col1, col2, data):\n",
    "    # Drop rows with missing values in either column\n",
    "    sub = data[[col1, col2]].dropna()\n",
    "    # If no data or only one category or zero variance, return 0\n",
    "    if sub.empty or sub[col2].nunique() < 2 or sub[col1].var() == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Calculate total sum of squares (SST)\n",
    "    overall_mean = sub[col1].mean()\n",
    "    sst = ((sub[col1] - overall_mean) ** 2).sum()\n",
    "\n",
    "    # Calculate sum of squares between groups (SSB)\n",
    "    ssb = 0.0\n",
    "    for cat in sub[col2].unique():\n",
    "        group = sub[col1][sub[col2] == cat]\n",
    "        # group always has length > 0 since sub filtered\n",
    "        group_mean = group.mean()\n",
    "        ssb += len(group) * (group_mean - overall_mean) ** 2\n",
    "\n",
    "    # Eta squared is the ratio of explained variance to total variance\n",
    "    return ssb / sst if sst > 0 else 0.0\n",
    "\n",
    "# General function to compute association based on data types\n",
    "def compute_association(col1, col2, data, categorical_cols):\n",
    "    is_cat1 = col1 in categorical_cols\n",
    "    is_cat2 = col2 in categorical_cols\n",
    "\n",
    "    # Numerical vs Numerical\n",
    "    if not is_cat1 and not is_cat2:\n",
    "        return compute_pearson_corr(col1, col2, data)\n",
    "    # Categorical vs Categorical\n",
    "    elif is_cat1 and is_cat2:\n",
    "        return cramers_v(col1, col2, data)\n",
    "    # Numerical vs Categorical\n",
    "    else:\n",
    "        # Identify which is numerical and which is categorical\n",
    "        num_col, cat_col = (col1, col2) if not is_cat1 else (col2, col1)\n",
    "        return compute_eta_squared(num_col, cat_col, data)\n",
    "\n",
    "# Assuming 'train_features' is the input dataframe, 'filtered_features' is numerical, and 'categorical_cols' lists categorical columns\n",
    "columns = filtered_features\n",
    "n_jobs = -1  # Use all available cores\n",
    "\n",
    "# Generate the matrix in parallel\n",
    "association_values = Parallel(n_jobs=n_jobs)(\n",
    "    delayed(compute_association)(col1, col2, train_features, categorical_cols)\n",
    "    for col1 in columns for col2 in columns\n",
    ")\n",
    "\n",
    "# Reshape the list into a square matrix\n",
    "association_matrix = pd.DataFrame(\n",
    "    np.array(association_values).reshape(len(columns), len(columns)),\n",
    "    index=columns, columns=columns\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70b73cec-0de2-4380-8958-ce820a4cf82e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Convert pandas DF to dask DF\n",
    "ddf = dd.from_pandas(train_features, npartitions=24)  # adjust partitions\n",
    "\n",
    "def cramers_v_dask(col1, col2, ddf):\n",
    "    # Compute contingency table with dask\n",
    "    confusion_matrix = pd.crosstab(df[col1], df[col2])  # safe, no duplicate index issues\n",
    "    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))    \n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "\n",
    "def eta_squared_dask(num_col, cat_col, ddf):\n",
    "    sub = ddf[[num_col, cat_col]].dropna().compute()\n",
    "    if sub.empty or sub[cat_col].nunique() < 2 or sub[num_col].var() == 0:\n",
    "        return 0.0\n",
    "\n",
    "    overall_mean = sub[num_col].mean()\n",
    "    sst = ((sub[num_col] - overall_mean) ** 2).sum()\n",
    "    ssb = sum(len(group) * (group.mean() - overall_mean) ** 2 \n",
    "              for _, group in sub.groupby(cat_col)[num_col])\n",
    "    return ssb / sst if sst > 0 else 0.0\n",
    "\n",
    "def pearson_corr_dask(col1, col2, ddf):\n",
    "    return ddf[col1].corr(ddf[col2]).compute()\n",
    "\n",
    "def compute_association_dask(col1, col2, ddf, categorical_cols):\n",
    "    is_cat1 = col1 in categorical_cols\n",
    "    is_cat2 = col2 in categorical_cols\n",
    "    if col1 == col2:\n",
    "        return 1.0\n",
    "    if not is_cat1 and not is_cat2:\n",
    "        return pearson_corr_dask(col1, col2, ddf)\n",
    "    elif is_cat1 and is_cat2:\n",
    "        return cramers_v_dask(col1, col2, ddf)\n",
    "    else:\n",
    "        num_col, cat_col = (col1, col2) if not is_cat1 else (col2, col1)\n",
    "        return eta_squared_dask(num_col, cat_col, ddf)\n",
    "\n",
    "def compute_association_matrix_dask(ddf, cols, categorical_cols, n_jobs=-1):\n",
    "    pairs = list(itertools.combinations_with_replacement(cols, 2))\n",
    "\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(compute_association_dask)(c1, c2, ddf, categorical_cols) \n",
    "        for c1, c2 in pairs\n",
    "    )\n",
    "\n",
    "    mat = pd.DataFrame(np.eye(len(cols)), index=cols, columns=cols)\n",
    "    for (c1, c2), val in zip(pairs, results):\n",
    "        mat.loc[c1, c2] = val\n",
    "        mat.loc[c2, c1] = val\n",
    "    return mat\n",
    "\n",
    "# Run\n",
    "association_matrix = compute_association_matrix_dask(ddf, filtered_features, categorical_cols)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47ee56fa-0125-4836-93b5-adc34d334eb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plot the heatmap\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(association_matrix.abs(), annot=True, cmap='coolwarm', fmt=\".3f\", linewidths=0.5, annot_kws={\"size\": 10})\n",
    "plt.title('Correlation and Association Heatmap (Eta Squared for Num vs Cat)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cf2c016-3b9b-491b-a885-491f7e81b2c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 highly associated pairs (cutoff=0.6).\n",
      "Dropped 2 features: ['min_monthly_surplus_L12M', 'avg_monthly_cc_due_balance_L12M']\n",
      "Remaining features (60)\n"
     ]
    }
   ],
   "source": [
    "# Set cutoff for high association\n",
    "cutoff = 0.6\n",
    "# Use upper triangle of the association matrix to avoid duplicate pairs\n",
    "upper_triangle = association_matrix.where(np.triu(np.ones(association_matrix.shape), k=1).astype(bool))\n",
    "# Find all feature pairs with association above the cutoff\n",
    "correlated_pairs = [\n",
    "    (col, row)\n",
    "    for col in upper_triangle.columns\n",
    "    for row in upper_triangle.index\n",
    "    if upper_triangle.abs().at[row, col] > cutoff\n",
    "]\n",
    "\n",
    "print(f\"Found {len(correlated_pairs)} highly associated pairs (cutoff={cutoff}).\")\n",
    "\n",
    "# Determine which features to drop based on SHAP importance\n",
    "# Assuming 'shap_abs' is a Series of absolute SHAP values indexed by feature\n",
    "drop_set = set()\n",
    "for col, row in correlated_pairs:\n",
    "    \n",
    "    if col in forced_columns and row in forced_columns:\n",
    "        if shap_abs.loc[col] > shap_abs.loc[row]:\n",
    "            drop_set.add(row)\n",
    "        else:\n",
    "            drop_set.add(col)\n",
    "    \n",
    "    elif col in forced_columns:\n",
    "        drop_set.add(row)\n",
    "    elif row in forced_columns:\n",
    "        drop_set.add(col)\n",
    "\n",
    "    elif shap_abs.loc[col] > shap_abs.loc[row]:\n",
    "        drop_set.add(row)\n",
    "    else:\n",
    "        drop_set.add(col)\n",
    "\n",
    "# Final filtered feature list\n",
    "drop_set = list(drop_set)\n",
    "filtered_features = [col for col in filtered_features if col not in drop_set]\n",
    "\n",
    "print(f\"Dropped {len(drop_set)} features: {drop_set}\")\n",
    "print(f\"Remaining features ({len(filtered_features)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "312beda5-c64a-4783-b088-23d2dfb6a214",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['min_total_monthly_expense_L12M',\n",
       " 'max_total_monthly_expense_L12M',\n",
       " 'max_monthly_surplus_L12M',\n",
       " 'most_frequent_bank',\n",
       " 'bank_with_highest_avg_balance',\n",
       " 'sum_monthly_debit_L3M',\n",
       " 'max_monthly_bankbalance_L6M',\n",
       " 'latest_txn_date_L9M',\n",
       " 'avg_monthly_cc_repayment',\n",
       " 'avg_monthly_cc_due_balance_L1M',\n",
       " 'avg_monthly_cc_due_amount_L3M',\n",
       " 'bank_w_highest_cc_limit',\n",
       " 'sum_total_credit_limit',\n",
       " 'max_cc_due_amount',\n",
       " 'avg_cc_repayment_L1M',\n",
       " 'unpaid_cc_status_avg_due_amount_L1M',\n",
       " 'fully_paid_cc_status_avg_due_amount_L3M',\n",
       " 'fully_paid_cc_status_avg_repayment_L3M',\n",
       " 'unknown_cc_status_avg_due_amount_L3M',\n",
       " 'avg_monthly_investment_count_L6M',\n",
       " 'provident_fund_investment_count_ALL',\n",
       " 'avg_investment_amt_L3M',\n",
       " 'min_investment_amt_L3M',\n",
       " 'fixed_deposit_total_investment_amt_L6M',\n",
       " 'provident_fund_avg_investment_amt_L6M',\n",
       " 'min_utility_paid_amount',\n",
       " 'avg_utility_paid_amount',\n",
       " 'avg_utility_due_amount',\n",
       " 'unique_payment_modes_count',\n",
       " 'bills_utilities_avg_topspend_amount',\n",
       " 'cash_withdrawal_avg_topspend_amount',\n",
       " 'charges_avg_topspend_amount',\n",
       " 'education_avg_topspend_amount',\n",
       " 'emi_repayment_count_topspend',\n",
       " 'emi_repayment_avg_topspend_amount',\n",
       " 'food_alcohol_avg_topspend_amount',\n",
       " 'gaming_count_topspend',\n",
       " 'gaming_avg_topspend_amount',\n",
       " 'groceries_count_topspend',\n",
       " 'groceries_avg_topspend_amount',\n",
       " 'insurance_count_topspend',\n",
       " 'insurance_avg_topspend_amount',\n",
       " 'medical_count_topspend',\n",
       " 'medical_avg_topspend_amount',\n",
       " 'online_shopping_avg_topspend_amount',\n",
       " 'p2m_avg_topspend_amount',\n",
       " 'p2p_count_topspend',\n",
       " 'p2p_avg_topspend_amount',\n",
       " 'travel_avg_topspend_amount',\n",
       " 'upi_avg_topspend_amount',\n",
       " 'vehicle_expenses_avg_topspend_amount',\n",
       " 'max_spend_category',\n",
       " 'total_no_of_insurance_policies',\n",
       " 'insurance_avg_due_amount',\n",
       " 'others_insurance_count_of_policies',\n",
       " 'IsGymLover',\n",
       " 'mf_purchased_inapp',\n",
       " 'age_bracket',\n",
       " 'tier',\n",
       " 'IsParent']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "766cb0b7-6ccd-491c-9b06-e7678d88a12b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IsParent',\n",
       " 'age_bracket',\n",
       " 'bank_with_highest_avg_balance',\n",
       " 'insurance_avg_topspend_amount',\n",
       " 'max_total_monthly_expense_L12M',\n",
       " 'latest_txn_date_L9M',\n",
       " 'emi_repayment_avg_topspend_amount',\n",
       " 'most_frequent_bank',\n",
       " 'max_monthly_surplus_L12M',\n",
       " 'max_monthly_bankbalance_L6M',\n",
       " 'bank_w_highest_cc_limit',\n",
       " 'min_investment_amt_L3M',\n",
       " 'others_insurance_count_of_policies',\n",
       " 'upi_avg_topspend_amount',\n",
       " 'provident_fund_avg_investment_amt_L6M',\n",
       " 'avg_utility_paid_amount',\n",
       " 'sum_monthly_debit_L3M',\n",
       " 'emi_repayment_count_topspend',\n",
       " 'insurance_count_topspend',\n",
       " 'avg_monthly_investment_count_L6M']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 20\n",
    "shap_ranked = (\n",
    "    shap_abs[shap_abs.index.isin(filtered_features)]\n",
    "    .drop(forced_columns, errors=\"ignore\")  # drop forced features to avoid duplication\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "remaining_slots = k - len(forced_columns)\n",
    "top_remaining = shap_ranked.head(remaining_slots).index.tolist()\n",
    "top_features = list(dict.fromkeys(forced_columns + top_remaining))  # preserve order, avoid dupes\n",
    "\n",
    "top_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78b4c5e-ee8c-4c76-861b-086ccacf4093",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d23b2c-122d-47fb-aaeb-8d3ac4589923",
   "metadata": {},
   "source": [
    "### Load Traning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7216b4a1-4ec4-4e15-bc75-558d5aa7d6a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Including Bureau Features\n",
    "top_features = [\n",
    "    'bank_with_highest_avg_balance',\n",
    "    'OVERDUE_BY_BALANCE_RATIO_SECURED_CURRENTLY_ACTIVE_SUM',\n",
    "    'util_increase_count_L6M_AVG',\n",
    "    'LOAN_AMT_NONMORTGAGE_CURRENTLY_INACTIVE_MAX',\n",
    "    'most_frequent_bank',\n",
    "    'AMT_OVERDUE_NONCC_REPORTED_L6M_MAX',\n",
    "    'VINTAGE_MAX',\n",
    "    'AMT_OVERDUE_UNSECURED_MAX',\n",
    "    'LOAN_AMT_CC_MAX',\n",
    "    'sum_monthly_credit_L9M',\n",
    "    'LOAN_AMT_ALL_OLDER_L6M_SUM',\n",
    "    'bank_w_highest_cc_limit',\n",
    "    'latest_txn_date_L12M',\n",
    "    'OVERDUE_BY_BALANCE_RATIO_ALL_OPENED_L12M_SUM',\n",
    "    'AMT_OVERDUE_PL_CURRENTLY_ACTIVE_SUM',\n",
    "    'COUNT_LOAN_PL_ALL_RATIO',\n",
    "    'OVERDUE_BY_BALANCE_RATIO_SECURED_SUM',\n",
    "    'UTIL_AMT_CC_SUM',\n",
    "    'AMT_OVERDUE_UNSECURED_OPENED_L12M_CURRENTLY_ACTIVE_MAX',\n",
    "    'LOAN_AMT_UNSECURED_OPENED_L12M_MAX'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf422f4-063a-45d5-bd0d-344941400d25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Not Including Bureau Features\n",
    "top_features = [\n",
    "    'bank_w_highest_loan_emi_due',\n",
    "    'unique_loan_accounts',\n",
    "    'age_bracket',\n",
    "    'bank_with_highest_avg_balance',\n",
    "    'cashflow_num_months',\n",
    "    'bank_w_highest_cc_limit',\n",
    "    'insurance_avg_topspend_amount',\n",
    "    'total_no_of_insurance_policies',\n",
    "    'medical_avg_topspend_amount',\n",
    "    'vehicle_expenses_avg_topspend_amount',\n",
    "    'max_total_monthly_inflow_L12M',\n",
    "    'most_frequent_bank',\n",
    "    'avg_monthly_credit_L9M',\n",
    "    'shopping_purchase_avg_topspend_amount',\n",
    "    'avg_monthly_bankbalance_L12M',\n",
    "    'gaming_avg_topspend_amount',\n",
    "    'min_monthly_bankbalance_ALL',\n",
    "    'tier',\n",
    "    'min_total_credit_limit',\n",
    "    'gaming_count_topspend'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "79ebb613-4635-475a-bb62-94c2f5da1bca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_features = [\n",
    "    'tier',\n",
    "    'age_bracket',\n",
    "    'dha_interacted',\n",
    "    'IsGymLover',\n",
    "    'bank_with_highest_avg_balance',\n",
    "    'cashflow_num_months',\n",
    "    'most_frequent_bank',\n",
    "    'bank_w_highest_cc_limit',\n",
    "    'max_total_monthly_inflow_L12M',\n",
    "    'avg_monthly_bankbalance_ALL',\n",
    "    'medical_avg_topspend_amount',\n",
    "    'emi_repayment_avg_topspend_amount',\n",
    "    'insurance_avg_topspend_amount',\n",
    "    'vehicle_expenses_avg_topspend_amount',\n",
    "    'min_monthly_bankbalance_ALL',\n",
    "    'avg_monthly_utility_due_amount_L12M',\n",
    "    'total_no_of_insurance_policies',\n",
    "    'gaming_count_topspend',\n",
    "    'sum_total_credit_limit',\n",
    "    'groceries_avg_topspend_amount'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15af9e11-77b7-42a2-8ae6-624881b9352e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_features = [\n",
    "    'tier',\n",
    "    'age_bracket',\n",
    "    'dha_interacted',\n",
    "    'bank_with_highest_avg_balance',\n",
    "    'cashflow_num_months',\n",
    "    'max_total_monthly_inflow_L12M',\n",
    "    'most_frequent_bank',\n",
    "    'bank_w_highest_cc_limit',\n",
    "    'avg_monthly_bankbalance_ALL',\n",
    "    'insurance_avg_topspend_amount',\n",
    "    'medical_avg_topspend_amount',\n",
    "    'emi_repayment_avg_topspend_amount',\n",
    "    'vehicle_expenses_avg_topspend_amount',\n",
    "    'min_monthly_bankbalance_ALL',\n",
    "    'total_no_of_insurance_policies',\n",
    "    'avg_monthly_utility_due_amount_L12M',\n",
    "    'gaming_avg_topspend_amount',\n",
    "    'avg_monthly_utility_paid_amount',\n",
    "    'sum_total_credit_limit',\n",
    "    'max_cc_repayment_L12M'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b648367-1e1c-49cc-9357-0cd4a64be492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_features = [\n",
    "    'IsParent',\n",
    "    'age_bracket',\n",
    "    'bank_with_highest_avg_balance',\n",
    "    'insurance_avg_topspend_amount',\n",
    "    'max_total_monthly_expense_L12M',\n",
    "    'latest_txn_date_L9M',\n",
    "    'emi_repayment_avg_topspend_amount',\n",
    "    'most_frequent_bank',\n",
    "    'max_monthly_surplus_L12M',\n",
    "    'max_monthly_bankbalance_L6M',\n",
    "    'bank_w_highest_cc_limit',\n",
    "    'min_investment_amt_L3M',\n",
    "    'others_insurance_count_of_policies',\n",
    "    'upi_avg_topspend_amount',\n",
    "    'provident_fund_avg_investment_amt_L6M',\n",
    "    'avg_utility_paid_amount',\n",
    "    'sum_monthly_debit_L3M',\n",
    "    'emi_repayment_count_topspend',\n",
    "    'insurance_count_topspend',\n",
    "    'avg_monthly_investment_count_L6M'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9665603f-d54c-4c6f-92a0-42d39527aaef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IsParent, age_bracket, bank_with_highest_avg_balance, insurance_avg_topspend_amount, max_total_monthly_expense_L12M, latest_txn_date_L9M, emi_repayment_avg_topspend_amount, most_frequent_bank, max_monthly_surplus_L12M, max_monthly_bankbalance_L6M, bank_w_highest_cc_limit, min_investment_amt_L3M, others_insurance_count_of_policies, upi_avg_topspend_amount, provident_fund_avg_investment_amt_L6M, avg_utility_paid_amount, sum_monthly_debit_L3M, emi_repayment_count_topspend, insurance_count_topspend, avg_monthly_investment_count_L6M'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_query = ', '.join(top_features)\n",
    "feature_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5129897-135f-4c7a-8420-6a4681c516f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17766174 entries, 0 to 17766173\n",
      "Data columns (total 23 columns):\n",
      " #   Column                                 Dtype  \n",
      "---  ------                                 -----  \n",
      " 0   customer_id                            object \n",
      " 1   snapshot_partition                     dbdate \n",
      " 2   target                                 Int64  \n",
      " 3   IsParent                               object \n",
      " 4   age_bracket                            object \n",
      " 5   bank_with_highest_avg_balance          object \n",
      " 6   insurance_avg_topspend_amount          float64\n",
      " 7   max_total_monthly_expense_L12M         float64\n",
      " 8   latest_txn_date_L9M                    object \n",
      " 9   emi_repayment_avg_topspend_amount      float64\n",
      " 10  most_frequent_bank                     object \n",
      " 11  max_monthly_surplus_L12M               float64\n",
      " 12  max_monthly_bankbalance_L6M            float64\n",
      " 13  bank_w_highest_cc_limit                object \n",
      " 14  min_investment_amt_L3M                 float64\n",
      " 15  others_insurance_count_of_policies     Int64  \n",
      " 16  upi_avg_topspend_amount                float64\n",
      " 17  provident_fund_avg_investment_amt_L6M  float64\n",
      " 18  avg_utility_paid_amount                float64\n",
      " 19  sum_monthly_debit_L3M                  float64\n",
      " 20  emi_repayment_count_topspend           Int64  \n",
      " 21  insurance_count_topspend               Int64  \n",
      " 22  avg_monthly_investment_count_L6M       float64\n",
      "dtypes: Int64(4), dbdate(1), float64(11), object(7)\n",
      "memory usage: 3.1+ GB\n"
     ]
    }
   ],
   "source": [
    "QUERY = f\"\"\"\n",
    "    SELECT DISTINCT\n",
    "        customer_id, snapshot_partition, abli_target AS target, {feature_query}\n",
    "    FROM\n",
    "        `abcd-dataplatform.abcd_data_science_app.li_intent_model_combined_features`\n",
    "    WHERE\n",
    "        snapshot_partition < '2025-04-30'\n",
    "\"\"\"\n",
    "\n",
    "train_set = client.query(QUERY).to_dataframe()\n",
    "train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7db1615c-1176-4e11-bc7a-32db2d0f0395",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17766174"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.groupby(['customer_id', 'snapshot_partition']).ngroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aecb9e0-ee34-44e5-ac54-8b171c93322f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14790426 entries, 0 to 14790425\n",
      "Data columns (total 23 columns):\n",
      " #   Column                                 Dtype  \n",
      "---  ------                                 -----  \n",
      " 0   customer_id                            object \n",
      " 1   snapshot_partition                     dbdate \n",
      " 2   target                                 Int64  \n",
      " 3   IsParent                               object \n",
      " 4   age_bracket                            object \n",
      " 5   bank_with_highest_avg_balance          object \n",
      " 6   insurance_avg_topspend_amount          float64\n",
      " 7   max_total_monthly_expense_L12M         float64\n",
      " 8   latest_txn_date_L9M                    object \n",
      " 9   emi_repayment_avg_topspend_amount      float64\n",
      " 10  most_frequent_bank                     object \n",
      " 11  max_monthly_surplus_L12M               float64\n",
      " 12  max_monthly_bankbalance_L6M            float64\n",
      " 13  bank_w_highest_cc_limit                object \n",
      " 14  min_investment_amt_L3M                 float64\n",
      " 15  others_insurance_count_of_policies     Int64  \n",
      " 16  upi_avg_topspend_amount                float64\n",
      " 17  provident_fund_avg_investment_amt_L6M  float64\n",
      " 18  avg_utility_paid_amount                float64\n",
      " 19  sum_monthly_debit_L3M                  float64\n",
      " 20  emi_repayment_count_topspend           Int64  \n",
      " 21  insurance_count_topspend               Int64  \n",
      " 22  avg_monthly_investment_count_L6M       float64\n",
      "dtypes: Int64(4), dbdate(1), float64(11), object(7)\n",
      "memory usage: 2.6+ GB\n"
     ]
    }
   ],
   "source": [
    "train_set = train_set[train_set[top_features].notna().any(axis=1)].reset_index(drop=True)\n",
    "train_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6fc50b-fabd-42cc-8ba8-c424092ade77",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e01fe83d-a488-45c7-8084-adcfff4fb18c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_cols_filtered = [col for col in top_features if col in date_cols]\n",
    "categorical_cols_filtered = [col for col in top_features if col in categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c660c65d-591b-4b7a-81b0-00fec02068c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dmatrix(df, date_cols, categorical_cols, label=None):\n",
    "    global train_features\n",
    "    \n",
    "    # Convert date columns to days between dates\n",
    "    if date_cols:\n",
    "        for date_col in date_cols:\n",
    "            df[date_col] = (pd.to_datetime(df.loc[:, 'snapshot_partition']) + pd.DateOffset(months=1) - pd.DateOffset(days=1) - pd.to_datetime(df.loc[:, date_col])).dt.days\n",
    "\n",
    "    # Label encode categorical columns\n",
    "    if categorical_cols:\n",
    "        for col in categorical_cols:\n",
    "            df[col]=df[col].astype('category')\n",
    "            \n",
    "\n",
    "    # Prepare the training data by filtering out unwanted columns\n",
    "    train_features = df.loc[:, ~(df.columns.str.contains('customer_id') |\n",
    "                                 df.columns.str.contains('mobilenumber') |\n",
    "                                 df.columns.str.contains('registration_date') |\n",
    "                                 df.columns.str.contains('digital_flag') |\n",
    "                                 df.columns.str.contains('app_flag') |\n",
    "                                 df.columns.str.contains('snapshot_partition'))]\n",
    "    \n",
    "    # Create a DMatrix for training\n",
    "    dmat = xgb.DMatrix(train_features, label=label, enable_categorical=True)\n",
    "    return dmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e218064-ffe2-4752-aea0-e8e8b7df3aea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation pass: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [22:50<00:00, 274.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy across 5 folds: 0.9994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ginis = []\n",
    "train_ginis = []\n",
    "train_events = []\n",
    "events = []\n",
    "num_events = []\n",
    "train_num_events = []\n",
    "models = []\n",
    "split_indices = []\n",
    "\n",
    "# StratifiedShuffleSplit configuration\n",
    "n_splits = 5  # Number of splits\n",
    "test_size = 0.2  # 20% for validation\n",
    "\n",
    "# Assuming `X` is your features and `y` is your target\n",
    "sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=42)\n",
    "\n",
    "# Track accuracy scores across splits (use a different metric if needed)\n",
    "scores = []\n",
    "previous_model = None\n",
    "eval_pass = 0\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(tqdm(sss.split(train_set[top_features + ['snapshot_partition']], train_set['target']), desc='Evaluation pass', total=n_splits)):\n",
    "    \n",
    "    split_indices.append((train_index, val_index))\n",
    "    X_train, X_val = train_set.loc[train_index, top_features + ['snapshot_partition']], train_set.loc[val_index, top_features + ['snapshot_partition']]\n",
    "    y_train, y_val = train_set.loc[train_index, 'target'], train_set.loc[val_index, 'target']\n",
    "\n",
    "    # Convert to DMatrix for XGBoost\n",
    "    dtrain = create_dmatrix(X_train, date_cols=date_cols_filtered, categorical_cols=categorical_cols_filtered, label=y_train)\n",
    "    dval = create_dmatrix(X_val, label=y_val, date_cols=date_cols_filtered, categorical_cols=categorical_cols_filtered)\n",
    "\n",
    "    # Train the model\n",
    "    evals = [(dtrain, 'train'), (dval, 'val')]\n",
    "    model = xgb.train(\n",
    "        params=xgb_feature_params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=500,\n",
    "        evals=evals,\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False\n",
    "        # xgb_model=previous_model\n",
    "    )\n",
    "    \n",
    "    models.append(model)\n",
    "#     previous_model = model_dart\n",
    "\n",
    "    # Predict and calculate accuracy (replace with a different evaluation metric if needed)\n",
    "    y_pred = model.predict(dval)\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)  # Assuming a binary classification problem\n",
    "    y_true = dval.get_label()\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred_binary)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    ginis.append(2*auc - 1)\n",
    "\n",
    "    y_pred = model.predict(dtrain)\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)  # Assuming a binary classification problem\n",
    "    y_true = dtrain.get_label()\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    train_ginis.append(2*auc - 1)\n",
    "    scores.append(accuracy)\n",
    "    \n",
    "    train_events.append(y_train.sum() / X_train.shape[0])\n",
    "    events.append(y_val.sum() / X_val.shape[0])\n",
    "\n",
    "    train_num_events.append(y_train.sum())\n",
    "    num_events.append(y_val.sum())\n",
    "    \n",
    "    eval_pass += 1\n",
    "    # print(f\"Evaluation Pass {eval_pass} Completed!\")\n",
    "\n",
    "# Print average accuracy\n",
    "print(f\"Average Accuracy across {n_splits} folds: {np.mean(scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2ff469-b280-4cd3-a101-8449777190fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Metrics and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c404913e-e267-4fad-8dcc-a5186b89a996",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model x Fold: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [56:35<00:00, 135.81s/it, Model=5, Fold=5, Val Gini=78.91%, Train Gini=80.44%]\n"
     ]
    }
   ],
   "source": [
    "cross_val_train_ginis = []\n",
    "cross_val_ginis = []\n",
    "\n",
    "pbar = tqdm(product(range(len(models)), range(len(split_indices))),\n",
    "            total=len(models)*len(split_indices),\n",
    "            desc=\"Model x Fold\")\n",
    "\n",
    "for i, j in pbar:\n",
    "    \n",
    "    train_index = split_indices[j][0]\n",
    "    val_index = split_indices[j][1]\n",
    "\n",
    "    X_train, X_val = train_set.loc[train_index, top_features + ['snapshot_partition']], train_set.loc[val_index, top_features + ['snapshot_partition']]\n",
    "    y_train, y_val = train_set.loc[train_index, 'target'], train_set.loc[val_index, 'target']\n",
    "\n",
    "    # Convert to DMatrix for XGBoost\n",
    "    dtrain = create_dmatrix(X_train, date_cols=date_cols_filtered, categorical_cols=categorical_cols_filtered, label=y_train)\n",
    "    dval = create_dmatrix(X_val, label=y_val, date_cols=date_cols_filtered, categorical_cols=categorical_cols_filtered)\n",
    "\n",
    "    y_pred = models[i].predict(dval)\n",
    "    y_true = dval.get_label()\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    val_gini = 2*auc - 1\n",
    "    cross_val_ginis.append(val_gini)\n",
    "\n",
    "    y_pred = models[i].predict(dtrain)\n",
    "    y_true = dtrain.get_label()\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    train_gini = 2*auc - 1\n",
    "    cross_val_train_ginis.append(train_gini)\n",
    "\n",
    "    pbar.set_postfix({\n",
    "        \"Model\": i+1,\n",
    "        \"Fold\": j+1,\n",
    "        \"Val Gini\": f\"{val_gini*100:.2f}%\",\n",
    "        \"Train Gini\": f\"{train_gini*100:.2f}%\"\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5391c17-df1b-4175-93e7-f107b547ac5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- FOR VALIDATION --\n",
      "Average Gini = 79.34%, \n",
      "Maximum Gini = 80.86%\n",
      "Minimum Gini = 77.98%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\" -- FOR VALIDATION --\n",
    "Average Gini = {np.mean(cross_val_ginis) * 100:.2f}%, \n",
    "Maximum Gini = {np.max(cross_val_ginis) * 100:.2f}%\n",
    "Minimum Gini = {np.min(cross_val_ginis) * 100:.2f}%\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70b956e3-6e4a-4d5f-8d8c-8f130658483e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- FOR TRAINING --\n",
      "Average Gini = 80.18%, \n",
      "Maximum Gini = 80.59%\n",
      "Minimum Gini = 79.63%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\" -- FOR TRAINING --\n",
    "Average Gini = {np.mean(cross_val_train_ginis) * 100:.2f}%, \n",
    "Maximum Gini = {np.max(cross_val_train_ginis) * 100:.2f}%\n",
    "Minimum Gini = {np.min(cross_val_train_ginis) * 100:.2f}%\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c17419aa-bfd0-45f5-817f-5046c348e505",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cross_val_train_ginis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b9c94db-f651-46ca-82f9-2679aebc9fd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: Train Gini = 80.22%, Val Gini = 79.36%\n",
      "Model 2: Train Gini = 80.27%, Val Gini = 79.30%\n",
      "Model 3: Train Gini = 79.98%, Val Gini = 79.36%\n",
      "Model 4: Train Gini = 80.18%, Val Gini = 79.30%\n",
      "Model 5: Train Gini = 80.28%, Val Gini = 79.37%\n"
     ]
    }
   ],
   "source": [
    "# Define number of folds (assumed constant for all models)\n",
    "folds = 5\n",
    "models_count = len(cross_val_train_ginis) // folds  # Total number of models\n",
    "\n",
    "# Compute averages\n",
    "average_ginis = [\n",
    "    Box({\n",
    "        \"model\": f\"Model {i+1}\",\n",
    "        \"avg_train_gini\": sum(cross_val_train_ginis[i * folds : (i + 1) * folds]) / folds,\n",
    "        \"avg_val_gini\": sum(cross_val_ginis[i * folds : (i + 1) * folds]) / folds\n",
    "    })\n",
    "    for i in range(models_count)\n",
    "]\n",
    "# Print results\n",
    "for avg in average_ginis:\n",
    "    print(f\"{avg['model']}: Train Gini = {avg['avg_train_gini'] * 100:.2f}%, Val Gini = {avg['avg_val_gini'] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "247c84a9-2058-454e-b0fe-3c6a8878d569",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(ginis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a4e2437-a3af-4b07-a48b-ac6a467b1a29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stability = np.absolute([average_ginis[i].avg_train_gini - average_ginis[i].avg_val_gini for i in range(len(average_ginis))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ecde039-fee2-4e1c-84f0-6bb83459b9fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00856169, 0.00967157, 0.00616504, 0.00876319, 0.00911845])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4895dda-b035-4fb5-83c2-83fa5f862cf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- MODEL STABILITY --\n",
      "Average Gini Difference = 0.85%, \n",
      "Maximum Gini Difference = 0.97%\n",
      "Minimum Gini Difference = 0.62%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\" -- MODEL STABILITY --\n",
    "Average Gini Difference = {np.mean(stability) * 100:.2f}%, \n",
    "Maximum Gini Difference = {np.max(stability) * 100:.2f}%\n",
    "Minimum Gini Difference = {np.min(stability) * 100:.2f}%\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acb664f0-43f9-4c67-a5f0-639cfc2fda88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_stable_model = np.argmin(stability)\n",
    "most_stable_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f9f7624-6666-4358-9911-2eca82b39f9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_xgb_final = models[most_stable_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a231d7ed-8c17-4cc1-a26b-b9bb4139bf89",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e36cf099-4af9-4c35-a8e7-cc87c74ccacc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_xgb_final.save_model('li_intent_model_2025-10-07.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8943ab42-4da7-4b90-9f8d-912ee6ac5ebe",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb39cf85-7669-496e-af54-ec79c3ac258a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_xgb_final = xgb.Booster()\n",
    "model_xgb_final.load_model('li_intent_model_2025-10-07.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5edfd5-50a1-483e-9496-72778d524c06",
   "metadata": {},
   "source": [
    "### OOT Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e6dbcc5-1de7-45de-a3e0-86ea07223a0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5856022 entries, 0 to 5856021\n",
      "Data columns (total 25 columns):\n",
      " #   Column                                 Dtype  \n",
      "---  ------                                 -----  \n",
      " 0   customer_id                            object \n",
      " 1   snapshot_partition                     dbdate \n",
      " 2   sms_target                             Int64  \n",
      " 3   abli_target                            Int64  \n",
      " 4   final_target                           Int64  \n",
      " 5   IsParent                               object \n",
      " 6   age_bracket                            object \n",
      " 7   bank_with_highest_avg_balance          object \n",
      " 8   insurance_avg_topspend_amount          float64\n",
      " 9   max_total_monthly_expense_L12M         float64\n",
      " 10  latest_txn_date_L9M                    object \n",
      " 11  emi_repayment_avg_topspend_amount      float64\n",
      " 12  most_frequent_bank                     object \n",
      " 13  max_monthly_surplus_L12M               float64\n",
      " 14  max_monthly_bankbalance_L6M            float64\n",
      " 15  bank_w_highest_cc_limit                object \n",
      " 16  min_investment_amt_L3M                 float64\n",
      " 17  others_insurance_count_of_policies     Int64  \n",
      " 18  upi_avg_topspend_amount                float64\n",
      " 19  provident_fund_avg_investment_amt_L6M  float64\n",
      " 20  avg_utility_paid_amount                float64\n",
      " 21  sum_monthly_debit_L3M                  float64\n",
      " 22  emi_repayment_count_topspend           Int64  \n",
      " 23  insurance_count_topspend               Int64  \n",
      " 24  avg_monthly_investment_count_L6M       float64\n",
      "dtypes: Int64(6), dbdate(1), float64(11), object(7)\n",
      "memory usage: 1.1+ GB\n"
     ]
    }
   ],
   "source": [
    "QUERY = f\"\"\"\n",
    "    SELECT DISTINCT\n",
    "        customer_id, snapshot_partition, sms_target, abli_target, final_target, {feature_query}\n",
    "    FROM\n",
    "        `abcd-dataplatform.abcd_data_science_app.li_intent_model_combined_features`\n",
    "    WHERE\n",
    "        snapshot_partition = '2025-05-31'\n",
    "\"\"\"\n",
    "\n",
    "oot_set = client.query(QUERY).to_dataframe()\n",
    "oot_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "84af46a9-beaf-4465-92e2-d2092dda42f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4966820 entries, 0 to 4966819\n",
      "Data columns (total 25 columns):\n",
      " #   Column                                 Dtype  \n",
      "---  ------                                 -----  \n",
      " 0   customer_id                            object \n",
      " 1   snapshot_partition                     dbdate \n",
      " 2   sms_target                             Int64  \n",
      " 3   abli_target                            Int64  \n",
      " 4   final_target                           Int64  \n",
      " 5   IsParent                               object \n",
      " 6   age_bracket                            object \n",
      " 7   bank_with_highest_avg_balance          object \n",
      " 8   insurance_avg_topspend_amount          float64\n",
      " 9   max_total_monthly_expense_L12M         float64\n",
      " 10  latest_txn_date_L9M                    object \n",
      " 11  emi_repayment_avg_topspend_amount      float64\n",
      " 12  most_frequent_bank                     object \n",
      " 13  max_monthly_surplus_L12M               float64\n",
      " 14  max_monthly_bankbalance_L6M            float64\n",
      " 15  bank_w_highest_cc_limit                object \n",
      " 16  min_investment_amt_L3M                 float64\n",
      " 17  others_insurance_count_of_policies     Int64  \n",
      " 18  upi_avg_topspend_amount                float64\n",
      " 19  provident_fund_avg_investment_amt_L6M  float64\n",
      " 20  avg_utility_paid_amount                float64\n",
      " 21  sum_monthly_debit_L3M                  float64\n",
      " 22  emi_repayment_count_topspend           Int64  \n",
      " 23  insurance_count_topspend               Int64  \n",
      " 24  avg_monthly_investment_count_L6M       float64\n",
      "dtypes: Int64(6), dbdate(1), float64(11), object(7)\n",
      "memory usage: 975.8+ MB\n"
     ]
    }
   ],
   "source": [
    "oot_set = oot_set[oot_set[top_features].notna().any(axis=1)].reset_index(drop=True)\n",
    "oot_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4188141c-ceef-4a33-b935-998674585ae7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smaller_sets = [\n",
    "    (oot_set.drop(columns=['sms_target', 'abli_target']).rename(columns={'final_target': 'target'}), 'Combined Target'),\n",
    "    (oot_set.drop(columns=['sms_target', 'final_target']).rename(columns={'abli_target': 'target'}), 'LOB Target'),\n",
    "    (oot_set.drop(columns=['final_target', 'abli_target']).rename(columns={'sms_target': 'target'}), 'SMS Target'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "17d058dd-47ae-4fdf-9b6b-738bf374a8d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4966820, 23)\n",
      "(4966820, 23)\n",
      "(4966820, 23)\n"
     ]
    }
   ],
   "source": [
    "reports = []\n",
    "for df, snapshot in smaller_sets:\n",
    "    print(df.shape)\n",
    "    dmat = create_dmatrix(df[top_features + ['snapshot_partition']].copy(), date_cols=date_cols_filtered, categorical_cols=categorical_cols_filtered, label=df['target'].copy())\n",
    "    # Predict probabilities\n",
    "    y_pred = model_xgb_final.predict(dmat)\n",
    "\n",
    "    # Extract true labels from DMatrix\n",
    "    y_true = dmat.get_label()\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    # Calculate Gini\n",
    "    gini = 2 * auc - 1\n",
    "    \n",
    "    reports.append(Box(\n",
    "        {\n",
    "            'fold_snapshot': snapshot,\n",
    "            'fold_size': df.snapshot_partition.count(),\n",
    "            'fold_gini': gini,\n",
    "            'fold_auc': auc\n",
    "        }\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ad3a198-9eb8-4a16-a965-a62df7a1ac2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- FOR OUT OF TIME VALIDATION --\n",
      "Fold Snapshot: Combined Target | Fold Size: 4966820 | Fold Gini: 78.11%\n",
      "Fold Snapshot: LOB Target | Fold Size: 4966820 | Fold Gini: 74.13%\n",
      "Fold Snapshot: SMS Target | Fold Size: 4966820 | Fold Gini: 81.33%\n"
     ]
    }
   ],
   "source": [
    "print('-- FOR OUT OF TIME VALIDATION --')\n",
    "for report in reports:\n",
    "    print_str = f\"Fold Snapshot: {report.fold_snapshot} | Fold Size: {report.fold_size} | Fold Gini: {report.fold_gini * 100:.2f}%\"\n",
    "    print(print_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4eee3cf-5161-4747-afa9-de61bbac0c36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtrain = create_dmatrix(\n",
    "    oot_set.drop(columns=['sms_target', 'abli_target', 'final_target']).copy(), \n",
    "    date_cols=date_cols_filtered, \n",
    "    categorical_cols=categorical_cols_filtered, \n",
    "    label=oot_set.rename(columns={'final_target': 'target'})['target'].copy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "38d6f980-de89-4a63-84a0-4ed199c1166f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Decile</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Probability</th>\n",
       "      <th>Actual</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>decile_recall</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>Bin Size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>nunique</th>\n",
       "      <th>sum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>378929</td>\n",
       "      <td>4817.0</td>\n",
       "      <td>0.009698</td>\n",
       "      <td>0.694893</td>\n",
       "      <td>69.489326</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>314558</td>\n",
       "      <td>881.0</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>0.127092</td>\n",
       "      <td>82.198502</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>338281</td>\n",
       "      <td>509.0</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.073428</td>\n",
       "      <td>89.541260</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>260163</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.038084</td>\n",
       "      <td>93.349686</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>168556</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.023658</td>\n",
       "      <td>95.715523</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>153233</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.016734</td>\n",
       "      <td>97.388924</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>75064</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.008944</td>\n",
       "      <td>98.283325</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>115267</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.008656</td>\n",
       "      <td>99.148872</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>115124</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.005193</td>\n",
       "      <td>99.668205</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>129828</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Decile Probability          Actual response_rate decile_recall capture_rate  \\\n",
       "                mean nunique     sum                                            \n",
       "9     10    0.003002  378929  4817.0      0.009698      0.694893    69.489326   \n",
       "8      9    0.000727  314558   881.0      0.001774      0.127092    82.198502   \n",
       "7      8    0.000440  338281   509.0      0.001025      0.073428    89.541260   \n",
       "6      7    0.000297  260163   264.0      0.000532      0.038084    93.349686   \n",
       "5      6    0.000219  168556   164.0      0.000330      0.023658    95.715523   \n",
       "4      5    0.000178  153233   116.0      0.000234      0.016734    97.388924   \n",
       "3      4    0.000155   75064    62.0      0.000125      0.008944    98.283325   \n",
       "2      3    0.000134  115267    60.0      0.000121      0.008656    99.148872   \n",
       "1      2    0.000111  115124    36.0      0.000072      0.005193    99.668205   \n",
       "0      1    0.000085  129828    23.0      0.000046      0.003318   100.000000   \n",
       "\n",
       "  Bin Size  \n",
       "            \n",
       "9   496682  \n",
       "8   496682  \n",
       "7   496682  \n",
       "6   496682  \n",
       "5   496682  \n",
       "4   496682  \n",
       "3   496682  \n",
       "2   496682  \n",
       "1   496682  \n",
       "0   496682  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = dtrain.get_label()\n",
    "\n",
    "y_pred_proba = model_xgb_final.predict(dtrain)\n",
    "deciles = pd.qcut(pd.Series(y_pred_proba).rank(method='first'), q=10, labels=False, duplicates='raise') + 1\n",
    "deciles_df = pd.DataFrame({\n",
    "    'Probability': y_pred_proba,\n",
    "    'Actual': y_test,\n",
    "    'Decile': deciles,\n",
    "    'Bin Size': 1\n",
    "}).sort_values(['Decile', 'Probability'],ascending=False)\n",
    "\n",
    "agg_deciles_df = deciles_df.groupby('Decile').agg({\n",
    "    'Probability': ['mean', 'nunique'],\n",
    "    'Actual':'sum',\n",
    "    'Bin Size': 'sum'\n",
    "}).reset_index().sort_values(['Decile'], ascending=False)\n",
    "\n",
    "agg_deciles_df['response_rate'] = agg_deciles_df['Actual'] / agg_deciles_df['Bin Size']\n",
    "agg_deciles_df['decile_recall'] = agg_deciles_df['Actual'] / y_test.sum()\n",
    "agg_deciles_df['capture_rate'] = agg_deciles_df['Actual'].cumsum() * 100 / y_test.sum()\n",
    "agg_deciles_df['Bin Size'] = agg_deciles_df.pop('Bin Size')\n",
    "agg_deciles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3f7101d-f61d-49f3-9ab9-f79fffe7125a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtrain = create_dmatrix(\n",
    "    oot_set.drop(columns=['sms_target', 'abli_target', 'final_target']).copy(), \n",
    "    date_cols=date_cols_filtered, \n",
    "    categorical_cols=categorical_cols_filtered, \n",
    "    label=oot_set.rename(columns={'abli_target': 'target'})['target'].copy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2a969bcb-35bd-4db8-b8b1-2dec97054fc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Decile</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Probability</th>\n",
       "      <th>Actual</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>decile_recall</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>Bin Size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>nunique</th>\n",
       "      <th>sum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>378929</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>0.003634</td>\n",
       "      <td>0.653512</td>\n",
       "      <td>65.351196</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>314558</td>\n",
       "      <td>356.0</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.128892</td>\n",
       "      <td>78.240402</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>338281</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.073860</td>\n",
       "      <td>85.626358</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>260163</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.047067</td>\n",
       "      <td>90.333092</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>168556</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.035844</td>\n",
       "      <td>93.917450</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>153233</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.019913</td>\n",
       "      <td>95.908760</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>75064</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.013034</td>\n",
       "      <td>97.212166</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>115267</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.014482</td>\n",
       "      <td>98.660393</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>115124</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>99.565529</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>129828</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Decile Probability          Actual response_rate decile_recall capture_rate  \\\n",
       "                mean nunique     sum                                            \n",
       "9     10    0.003002  378929  1805.0      0.003634      0.653512    65.351196   \n",
       "8      9    0.000727  314558   356.0      0.000717      0.128892    78.240402   \n",
       "7      8    0.000440  338281   204.0      0.000411      0.073860    85.626358   \n",
       "6      7    0.000297  260163   130.0      0.000262      0.047067    90.333092   \n",
       "5      6    0.000219  168556    99.0      0.000199      0.035844    93.917450   \n",
       "4      5    0.000178  153233    55.0      0.000111      0.019913    95.908760   \n",
       "3      4    0.000155   75064    36.0      0.000072      0.013034    97.212166   \n",
       "2      3    0.000134  115267    40.0      0.000081      0.014482    98.660393   \n",
       "1      2    0.000111  115124    25.0      0.000050      0.009051    99.565529   \n",
       "0      1    0.000085  129828    12.0      0.000024      0.004345   100.000000   \n",
       "\n",
       "  Bin Size  \n",
       "            \n",
       "9   496682  \n",
       "8   496682  \n",
       "7   496682  \n",
       "6   496682  \n",
       "5   496682  \n",
       "4   496682  \n",
       "3   496682  \n",
       "2   496682  \n",
       "1   496682  \n",
       "0   496682  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = dtrain.get_label()\n",
    "\n",
    "y_pred_proba = model_xgb_final.predict(dtrain)\n",
    "deciles = pd.qcut(pd.Series(y_pred_proba).rank(method='first'), q=10, labels=False, duplicates='raise') + 1\n",
    "deciles_df = pd.DataFrame({\n",
    "    'Probability': y_pred_proba,\n",
    "    'Actual': y_test,\n",
    "    'Decile': deciles,\n",
    "    'Bin Size': 1\n",
    "}).sort_values(['Decile', 'Probability'],ascending=False)\n",
    "\n",
    "agg_deciles_df = deciles_df.groupby('Decile').agg({\n",
    "    'Probability': ['mean', 'nunique'],\n",
    "    'Actual':'sum',\n",
    "    'Bin Size': 'sum'\n",
    "}).reset_index().sort_values(['Decile'], ascending=False)\n",
    "\n",
    "agg_deciles_df['response_rate'] = agg_deciles_df['Actual'] / agg_deciles_df['Bin Size']\n",
    "agg_deciles_df['decile_recall'] = agg_deciles_df['Actual'] / y_test.sum()\n",
    "agg_deciles_df['capture_rate'] = agg_deciles_df['Actual'].cumsum() * 100 / y_test.sum()\n",
    "agg_deciles_df['Bin Size'] = agg_deciles_df.pop('Bin Size')\n",
    "agg_deciles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d8caa08f-fab8-456c-935c-ccfce1242e60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtrain = create_dmatrix(\n",
    "    oot_set.drop(columns=['sms_target', 'abli_target', 'final_target']).copy(), \n",
    "    date_cols=date_cols_filtered, \n",
    "    categorical_cols=categorical_cols_filtered, \n",
    "    label=oot_set.rename(columns={'sms_target': 'target'})['target'].copy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a96b1b92-a5a5-4060-8a94-a63a8eecba2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Decile</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Probability</th>\n",
       "      <th>Actual</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>decile_recall</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>Bin Size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>nunique</th>\n",
       "      <th>sum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>378929</td>\n",
       "      <td>3269.0</td>\n",
       "      <td>0.006582</td>\n",
       "      <td>0.731975</td>\n",
       "      <td>73.197495</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>314558</td>\n",
       "      <td>548.0</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.122705</td>\n",
       "      <td>85.467979</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>338281</td>\n",
       "      <td>316.0</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.070757</td>\n",
       "      <td>92.543663</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>260163</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.030228</td>\n",
       "      <td>95.566505</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>168556</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.015002</td>\n",
       "      <td>97.066727</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>153233</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.013883</td>\n",
       "      <td>98.454994</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>75064</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.005822</td>\n",
       "      <td>99.037170</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>115267</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.004478</td>\n",
       "      <td>99.485001</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>115124</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.002463</td>\n",
       "      <td>99.731300</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>129828</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.002687</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>496682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Decile Probability          Actual response_rate decile_recall capture_rate  \\\n",
       "                mean nunique     sum                                            \n",
       "9     10    0.003002  378929  3269.0      0.006582      0.731975    73.197495   \n",
       "8      9    0.000727  314558   548.0      0.001103      0.122705    85.467979   \n",
       "7      8    0.000440  338281   316.0      0.000636      0.070757    92.543663   \n",
       "6      7    0.000297  260163   135.0      0.000272      0.030228    95.566505   \n",
       "5      6    0.000219  168556    67.0      0.000135      0.015002    97.066727   \n",
       "4      5    0.000178  153233    62.0      0.000125      0.013883    98.454994   \n",
       "3      4    0.000155   75064    26.0      0.000052      0.005822    99.037170   \n",
       "2      3    0.000134  115267    20.0      0.000040      0.004478    99.485001   \n",
       "1      2    0.000111  115124    11.0      0.000022      0.002463    99.731300   \n",
       "0      1    0.000085  129828    12.0      0.000024      0.002687   100.000000   \n",
       "\n",
       "  Bin Size  \n",
       "            \n",
       "9   496682  \n",
       "8   496682  \n",
       "7   496682  \n",
       "6   496682  \n",
       "5   496682  \n",
       "4   496682  \n",
       "3   496682  \n",
       "2   496682  \n",
       "1   496682  \n",
       "0   496682  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = dtrain.get_label()\n",
    "\n",
    "y_pred_proba = model_xgb_final.predict(dtrain)\n",
    "deciles = pd.qcut(pd.Series(y_pred_proba).rank(method='first'), q=10, labels=False, duplicates='raise') + 1\n",
    "deciles_df = pd.DataFrame({\n",
    "    'Probability': y_pred_proba,\n",
    "    'Actual': y_test,\n",
    "    'Decile': deciles,\n",
    "    'Bin Size': 1\n",
    "}).sort_values(['Decile', 'Probability'],ascending=False)\n",
    "\n",
    "agg_deciles_df = deciles_df.groupby('Decile').agg({\n",
    "    'Probability': ['mean', 'nunique'],\n",
    "    'Actual':'sum',\n",
    "    'Bin Size': 'sum'\n",
    "}).reset_index().sort_values(['Decile'], ascending=False)\n",
    "\n",
    "agg_deciles_df['response_rate'] = agg_deciles_df['Actual'] / agg_deciles_df['Bin Size']\n",
    "agg_deciles_df['decile_recall'] = agg_deciles_df['Actual'] / y_test.sum()\n",
    "agg_deciles_df['capture_rate'] = agg_deciles_df['Actual'].cumsum() * 100 / y_test.sum()\n",
    "agg_deciles_df['Bin Size'] = agg_deciles_df.pop('Bin Size')\n",
    "agg_deciles_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e838583d-2237-4e51-aeb7-8492bc78de55",
   "metadata": {},
   "source": [
    "### Model Evaluation and Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ceafd74e-fabb-43aa-af3d-d8772a07297f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train_set.loc[:, top_features + ['snapshot_partition']]\n",
    "y_train = train_set.loc[:, 'target']\n",
    "dtrain = create_dmatrix(X_train, date_cols=date_cols_filtered, categorical_cols=categorical_cols_filtered, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "764718e7-7cd4-4a70-8d5c-8b9f8cd2e2b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14790426 entries, 0 to 14790425\n",
      "Data columns (total 20 columns):\n",
      " #   Column                                 Dtype   \n",
      "---  ------                                 -----   \n",
      " 0   IsParent                               category\n",
      " 1   age_bracket                            category\n",
      " 2   bank_with_highest_avg_balance          category\n",
      " 3   insurance_avg_topspend_amount          float64 \n",
      " 4   max_total_monthly_expense_L12M         float64 \n",
      " 5   latest_txn_date_L9M                    float64 \n",
      " 6   emi_repayment_avg_topspend_amount      float64 \n",
      " 7   most_frequent_bank                     category\n",
      " 8   max_monthly_surplus_L12M               float64 \n",
      " 9   max_monthly_bankbalance_L6M            float64 \n",
      " 10  bank_w_highest_cc_limit                category\n",
      " 11  min_investment_amt_L3M                 float64 \n",
      " 12  others_insurance_count_of_policies     Int64   \n",
      " 13  upi_avg_topspend_amount                float64 \n",
      " 14  provident_fund_avg_investment_amt_L6M  float64 \n",
      " 15  avg_utility_paid_amount                float64 \n",
      " 16  sum_monthly_debit_L3M                  float64 \n",
      " 17  emi_repayment_count_topspend           Int64   \n",
      " 18  insurance_count_topspend               Int64   \n",
      " 19  avg_monthly_investment_count_L6M       float64 \n",
      "dtypes: Int64(3), category(5), float64(12)\n",
      "memory usage: 1.8 GB\n"
     ]
    }
   ],
   "source": [
    "train_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f5f33c3-61e2-4d07-bde7-4f06f12a6c91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 50s, sys: 1.05 s, total: 25min 51s\n",
      "Wall time: 51.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "explainer = shap.TreeExplainer(model_xgb_final, feature_perturbation=\"tree_path_dependent\")\n",
    "shap_values = explainer.shap_values(dtrain, approximate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c38599b-ba49-4043-8e1d-41ef526c55b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def shap_numeric_summary(shap_values, X, sample_size=50000, save=False, out_dir=\"./shap_plots\"):\n",
    "    \"\"\"\n",
    "    SHAP beeswarm summary plot for numerical features only.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    shap_values : np.ndarray\n",
    "        SHAP values matrix (n_samples, n_features).\n",
    "    X : pd.DataFrame\n",
    "        Training features DataFrame.\n",
    "    sample_size : int, optional\n",
    "        Number of samples to randomly choose for plotting (default=50,000).\n",
    "    save : bool, optional\n",
    "        If True, saves the plot instead of showing it.\n",
    "    out_path : str, optional\n",
    "        Path to save the plot (if save=True).\n",
    "    \"\"\"\n",
    "    # Identify numerical columns\n",
    "    num_cols = X.select_dtypes(include=[\"float64\", \"Int64\"]).columns\n",
    "    num_indices = [list(X.columns).index(c) for c in num_cols]\n",
    "\n",
    "    # Subsample\n",
    "    if sample_size and len(X) > sample_size:\n",
    "        sample_idx = np.random.choice(X.index, size=sample_size, replace=False)\n",
    "    else:\n",
    "        sample_idx = X.index\n",
    "    \n",
    "    # Slice SHAP values + feature values\n",
    "    shap_values_num = shap_values[sample_idx][:, num_indices]\n",
    "    features_num = X.loc[sample_idx, num_cols].astype(float)\n",
    "\n",
    "    # Plot\n",
    "    shap.summary_plot(\n",
    "        shap_values_num,\n",
    "        features_num,\n",
    "        feature_names=num_cols,\n",
    "        show=not save  # suppress auto-show if saving\n",
    "    )\n",
    "\n",
    "    if save:\n",
    "        import os\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        plt.savefig(f\"{out_dir}/shap_numeric.png\", bbox_inches=\"tight\")\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0de6f062-7e05-493c-ad09-a62a35dcc88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_category_beeswarm(feature, shap_values, X, top_n=15, sample_size=50000, save=False, out_dir=\"./shap_plots/\"):\n",
    "    \"\"\"\n",
    "    Beeswarm-style SHAP visualization for categorical features.\n",
    "    \"\"\"\n",
    "    # Subsample if dataset is huge\n",
    "    if sample_size and len(X) > sample_size:\n",
    "        sample_idx = np.random.choice(X.index, size=sample_size, replace=False)\n",
    "        X = X.loc[sample_idx]\n",
    "        shap_values = shap_values[sample_idx]\n",
    "    \n",
    "    col_idx = list(X.columns).index(feature)\n",
    "    shap_vals = shap_values[:, col_idx]\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        \"category\": X[feature].astype(str),\n",
    "        \"shap\": shap_vals\n",
    "    })\n",
    "    \n",
    "    # Rank by mean |SHAP| and keep top-N categories\n",
    "    top_cats = (\n",
    "        df.groupby(\"category\")[\"shap\"]\n",
    "        .apply(lambda x: np.mean(np.abs(x)))\n",
    "        .nlargest(top_n)\n",
    "        .index\n",
    "    )\n",
    "    df = df[df[\"category\"].isin(top_cats)]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.stripplot(\n",
    "        x=\"shap\", y=\"category\", data=df,\n",
    "        jitter=0.3, alpha=0.5, orient=\"h\"\n",
    "    )\n",
    "    plt.title(f\"Beeswarm-style SHAP for {feature} (Top {top_n} categories)\")\n",
    "    plt.xlabel(\"SHAP value (impact on model output)\")\n",
    "    \n",
    "    if save:\n",
    "        import os\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        plt.savefig(f\"{out_dir}/shap_{feature}.png\", bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44c4c8d9-9bf8-417e-ad7b-56d5da00b1d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def shap_feature_importance_bar(shap_values, X, top_n=None, save=False, out_dir=\"./shap_plots\", out_path=\"shap_importance_bar.png\"):\n",
    "    \"\"\"\n",
    "    SHAP bar summary plot (mean absolute SHAP value per feature).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    shap_values : np.ndarray\n",
    "        SHAP values matrix (n_samples, n_features).\n",
    "    X : pd.DataFrame\n",
    "        Training features DataFrame.\n",
    "    top_n : int, optional\n",
    "        Show only top-N features by importance (default=None, show all).\n",
    "    save : bool, optional\n",
    "        If True, saves the plot instead of displaying it.\n",
    "    out_path : str, optional\n",
    "        Path to save the plot (if save=True).\n",
    "    \"\"\"\n",
    "    shap.summary_plot(\n",
    "        shap_values,\n",
    "        X,\n",
    "        plot_type=\"bar\",\n",
    "        max_display=top_n if top_n else None,\n",
    "        show=not save  # suppress auto-show if saving\n",
    "    )\n",
    "\n",
    "    if save:\n",
    "        import os\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        plt.savefig(f\"{out_dir}/{out_path}\", bbox_inches=\"tight\")\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a71c189-8c17-481d-8c63-c5b5d98f1d18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap_numeric_summary(shap_values, train_features, sample_size=50000, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ea1a4e8-7961-42fd-ab4c-fb9413694e67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_cols = train_features.select_dtypes(include=[\"category\"]).columns\n",
    "\n",
    "for feature in cat_cols:\n",
    "    shap_category_beeswarm(feature, shap_values, train_features, top_n=15, sample_size=50000, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c844648-5f5e-442f-b4c7-a7d1d88d1c17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap_feature_importance_bar(shap_values, train_features, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cef51a66-9725-44c8-954c-82e9f984fa79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0026672482"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_abs = pd.DataFrame(shap_values, columns=train_features.columns).abs().mean()\n",
    "shap_abs.loc['dha_interacted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e298c400-4e59-4761-8731-0bec3e007555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age_bracket', 'bank_with_highest_avg_balance', 'most_frequent_bank',\n",
       "       'latest_txn_date_ALL', 'insurance_avg_topspend_amount',\n",
       "       'avg_monthly_spend_amount_L1M', 'min_monthly_surplus_L9M',\n",
       "       'max_monthly_bankbalance_L3M', 'max_monthly_surplus_L12M',\n",
       "       'emi_repayment_count_topspend', 'avg_investment_amt_L3M',\n",
       "       'max_spend_category', 'min_monthly_bankbalance_ALL',\n",
       "       'insurance_count_topspend', 'p2a_avg_topspend_amount',\n",
       "       'median_monthly_utility_paid_amount_L6M', 'min_investment_amt_L3M',\n",
       "       'insurance_avg_due_amount', 'p2p_avg_topspend_amount',\n",
       "       'avg_monthly_investment_count_L3M'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696dd743-eaf7-4b92-835a-ea8842dbcefe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
